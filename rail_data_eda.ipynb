{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf7e15f-4b6d-4e0e-99e8-5bf70e936eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "# Creating a SparkSession\n",
    "spark = SparkSession.builder.appName(\"MySparkApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11255b-5f7f-4d56-8848-6e2a102d3b49",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30b3d88-5446-4260-8d53-d9f5761a8742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+------------------+-------------+--------------+-----------------+--------------------+----------------------+--------------------+----------------------+----+--------+------------+-------------------+---------------------+------------------+--------------------+-----------------+\n",
      "|       route_id|unique_id|service_start_date|update_origin|train_platform|working_time_pass|working_time_arrival|working_time_departure|planned_time_arrival|planned_time_departure|pass|platform|train_length|actual_arrival_time|actual_departure_time|is_delayed_arrival|is_delayed_departure|__index_level_0__|\n",
      "+---------------+---------+------------------+-------------+--------------+-----------------+--------------------+----------------------+--------------------+----------------------+----+--------+------------+-------------------+---------------------+------------------+--------------------+-----------------+\n",
      "|202307277679020|   L79020|        2023-07-27|       Darwin|          STFD|             NULL| 2023-07-27 00:03:00|   2023-07-27 00:03:30|                NULL|                  NULL|NULL|       5|        NULL|2023-07-27 00:53:00|  2023-07-27 00:53:00|              true|                true|                8|\n",
      "|202307277679020|   L79020|        2023-07-27|       Darwin|       SPNY205|             NULL| 2023-07-27 00:07:00|   2023-07-27 00:13:30|                NULL|                  NULL|NULL|    NULL|        NULL|2023-07-27 00:57:00|  2023-07-27 00:58:00|              true|                true|               10|\n",
      "|202307277679020|   L79020|        2023-07-27|       Darwin|        PADTLL|             NULL| 2023-07-27 00:30:30|   2023-07-27 00:31:00|                NULL|                  NULL|NULL|       B|        NULL|2023-07-27 01:07:00|  2023-07-27 01:07:00|              true|                true|               16|\n",
      "|202307277679020|   L79020|        2023-07-27|       Darwin|       WBRNPKS|             NULL| 2023-07-27 00:33:00|   2023-07-27 00:35:00|                NULL|                  NULL|NULL|       A|        NULL|2023-07-27 01:09:00|  2023-07-27 01:10:00|              true|                true|               17|\n",
      "|202307277674553|   L74553|        2023-07-27|           TD|       SVNOAKS|             NULL| 2023-07-27 21:53:00|   2023-07-27 21:54:30| 2023-07-27 21:53:00|   2023-07-27 21:54:00|NULL|       1|           8|               NULL|                 NULL|             false|               false|               22|\n",
      "+---------------+---------+------------------+-------------+--------------+-----------------+--------------------+----------------------+--------------------+----------------------+----+--------+------------+-------------------+---------------------+------------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "df = spark.read.parquet('rail_data_cleaned_20230728132300.parquet')\n",
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289ce475-5521-4abc-895d-c2518c489555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- route_id: string (nullable = true)\n",
      " |-- unique_id: string (nullable = true)\n",
      " |-- service_start_date: string (nullable = true)\n",
      " |-- update_origin: string (nullable = true)\n",
      " |-- train_platform: string (nullable = true)\n",
      " |-- working_time_pass: timestamp_ntz (nullable = true)\n",
      " |-- working_time_arrival: timestamp_ntz (nullable = true)\n",
      " |-- working_time_departure: timestamp_ntz (nullable = true)\n",
      " |-- planned_time_arrival: timestamp_ntz (nullable = true)\n",
      " |-- planned_time_departure: timestamp_ntz (nullable = true)\n",
      " |-- pass: integer (nullable = true)\n",
      " |-- platform: string (nullable = true)\n",
      " |-- train_length: string (nullable = true)\n",
      " |-- actual_arrival_time: timestamp_ntz (nullable = true)\n",
      " |-- actual_departure_time: timestamp_ntz (nullable = true)\n",
      " |-- is_delayed_arrival: boolean (nullable = true)\n",
      " |-- is_delayed_departure: boolean (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print rows with respective datatypes\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f07edaf-0712-4512-9599-c7266fdb1ff0",
   "metadata": {},
   "source": [
    "## Check for Dups/ Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e23d76-3034-48fc-b86c-107b2eb1b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|      NULL|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find duplicate rows\n",
    "df.groupBy(df.columns)\\\n",
    "    .count()\\\n",
    "    .where(F.col('count') > 1)\\\n",
    "    .select(F.sum('count'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304982c4-aa35-433a-9893-9d2f3a38f337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'route_id': 0,\n",
       " 'unique_id': 0,\n",
       " 'service_start_date': 0,\n",
       " 'update_origin': 585,\n",
       " 'train_platform': 0,\n",
       " 'working_time_pass': 37100,\n",
       " 'working_time_arrival': 0,\n",
       " 'working_time_departure': 0,\n",
       " 'planned_time_arrival': 3245,\n",
       " 'planned_time_departure': 3520,\n",
       " 'pass': 37100,\n",
       " 'platform': 2986,\n",
       " 'train_length': 26505,\n",
       " 'actual_arrival_time': 5331,\n",
       " 'actual_departure_time': 2716,\n",
       " 'is_delayed_arrival': 0,\n",
       " 'is_delayed_departure': 0,\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a null count for all columns\n",
    "Dict_Null = {col:df.filter(df[col].isNull()).count() for col in df.columns}\n",
    "Dict_Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0ff85d-453f-4804-996d-d8bd05f18070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[route_id: string, unique_id: string, service_start_date: string, update_origin: string, train_platform: string, working_time_pass: timestamp_ntz, working_time_arrival: timestamp_ntz, working_time_departure: timestamp_ntz, planned_time_arrival: timestamp_ntz, planned_time_departure: timestamp_ntz, pass: int, platform: string, actual_arrival_time: timestamp_ntz, actual_departure_time: timestamp_ntz, is_delayed_arrival: boolean, is_delayed_departure: boolean, __index_level_0__: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove cols with too many null values\n",
    "df.drop('working_time_pass')\n",
    "df.drop('pass')\n",
    "df.drop('train_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ff3ba0-1590-4361-861e-2bace70751c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with null values from the dataset\n",
    "df = df.dropna(subset='planned_time_departure')\n",
    "df = df.dropna(subset='update_origin')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1bc847-2ac0-4ba5-9bd1-421dc42998f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in route_id:\n",
      "+---------------+-----+\n",
      "|       route_id|count|\n",
      "+---------------+-----+\n",
      "|202307278024592|   40|\n",
      "|202307278023407|    2|\n",
      "|202307287142024|    8|\n",
      "|202307277684886|    4|\n",
      "|202307277623421|    3|\n",
      "|202307277159156|    1|\n",
      "|202307278931917|    2|\n",
      "|202307278932995|   10|\n",
      "|202307277679446|    4|\n",
      "|202307288076176|    8|\n",
      "|202307288075928|   36|\n",
      "|202307278027471|    5|\n",
      "|202307287195442|    1|\n",
      "|202307278070469|    5|\n",
      "|202307277683900|    1|\n",
      "|202307278929733|    1|\n",
      "|202307277683740|    2|\n",
      "|202307287159171|    1|\n",
      "|202307277194734|    1|\n",
      "|202307277674757|    1|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Unique values in unique_id:\n",
      "+---------+-----+\n",
      "|unique_id|count|\n",
      "+---------+-----+\n",
      "|   L79822|   11|\n",
      "|   G59266|    1|\n",
      "|   P25443|    2|\n",
      "|   P24503|    9|\n",
      "|   C18264|   31|\n",
      "|   C16587|    1|\n",
      "|   P71715|    3|\n",
      "|   L34352|    2|\n",
      "|   L23434|    4|\n",
      "|   G95492|   10|\n",
      "|   L23565|    1|\n",
      "|   Y31409|   21|\n",
      "|   Y30069|    1|\n",
      "|   P27235|    5|\n",
      "|   G67331|    1|\n",
      "|   Y55093|    1|\n",
      "|   P75426|    3|\n",
      "|   G81189|    1|\n",
      "|   G70054|    1|\n",
      "|   P76316|    4|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Unique values in service_start_date:\n",
      "+------------------+-----+\n",
      "|service_start_date|count|\n",
      "+------------------+-----+\n",
      "|        2023-07-27|17962|\n",
      "|        2023-07-29|   56|\n",
      "|        2023-07-28|14986|\n",
      "+------------------+-----+\n",
      "\n",
      "Unique values in update_origin:\n",
      "+-------------+-----+\n",
      "|update_origin|count|\n",
      "+-------------+-----+\n",
      "|           TD|10059|\n",
      "|        Trust| 2052|\n",
      "|       Darwin| 6547|\n",
      "|  Workstation|   28|\n",
      "|       Tyrell|  283|\n",
      "|          CIS|14035|\n",
      "+-------------+-----+\n",
      "\n",
      "Unique values in train_platform:\n",
      "+--------------+-----+\n",
      "|train_platform|count|\n",
      "+--------------+-----+\n",
      "|       MRYLAND|   37|\n",
      "|       MINFORD|    5|\n",
      "|       SHENFLD|   37|\n",
      "|       BRITHDR|    3|\n",
      "|       HATHRSG|   10|\n",
      "|       HEATHHL|    7|\n",
      "|       TURKYST|   10|\n",
      "|       CLFDOWN|    5|\n",
      "|       RIDNGML|    3|\n",
      "|       HOLTONH|    4|\n",
      "|       NNRYSQU|    1|\n",
      "|       WODBDGE|    2|\n",
      "|          ELTR|   31|\n",
      "|          GTHM|   28|\n",
      "|       MCHYNLT|   12|\n",
      "|          DLTN|   22|\n",
      "|          SABR|   15|\n",
      "|       MEOLSCP|    2|\n",
      "|       SELLING|    4|\n",
      "|       STNEOTS|   18|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Unique values in platform:\n",
      "+--------+-----+\n",
      "|platform|count|\n",
      "+--------+-----+\n",
      "|      1L|    3|\n",
      "|       7|  203|\n",
      "|      1A|    7|\n",
      "|      15|   27|\n",
      "|     12A|    3|\n",
      "|      11|   67|\n",
      "|     10A|    7|\n",
      "|       3| 2756|\n",
      "|     16A|    2|\n",
      "|     16B|    1|\n",
      "|     FAL|    1|\n",
      "|     BUS|   33|\n",
      "|      8D|    3|\n",
      "|      1C|    2|\n",
      "|       8|  308|\n",
      "|      3B|   28|\n",
      "|      4B|   18|\n",
      "|      7A|    6|\n",
      "|      16|   29|\n",
      "|     15B|    3|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Unique values in train_length:\n",
      "+------------+-----+\n",
      "|train_length|count|\n",
      "+------------+-----+\n",
      "|           7|   45|\n",
      "|          11|    6|\n",
      "|           3|  788|\n",
      "|           8| 2629|\n",
      "|        NULL|23403|\n",
      "|           5| 1833|\n",
      "|           6|  471|\n",
      "|           9|    5|\n",
      "|          10| 1069|\n",
      "|           4| 1376|\n",
      "|          12|  955|\n",
      "|           2|  424|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark value_counts\n",
    "# get list of categorical var cols\n",
    "categorical_columns = [c for c in df.columns if df.select(c).dtypes[0][1] == 'string']\n",
    "\n",
    "# do a value counts for each categorical var\n",
    "for col_name in categorical_columns:\n",
    "    print(f\"Unique values in {col_name}:\")\n",
    "    df.groupBy(col_name).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0720d9b8-0faa-4fbb-ae50-be7235039311",
   "metadata": {},
   "source": [
    "## Merge Data with Rail References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d84d75d-83ac-4d14-98c6-42b40f221a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AtcoCode: string (nullable = true)\n",
      " |-- TiplocCode: string (nullable = true)\n",
      " |-- CrsCode: string (nullable = true)\n",
      " |-- StationName: string (nullable = true)\n",
      " |-- StationNameLang: string (nullable = true)\n",
      " |-- GridType: string (nullable = true)\n",
      " |-- Easting: integer (nullable = true)\n",
      " |-- Northing: integer (nullable = true)\n",
      " |-- CreationDateTime: timestamp (nullable = true)\n",
      " |-- ModificationDateTime: timestamp (nullable = true)\n",
      " |-- RevisionNumber: integer (nullable = true)\n",
      " |-- Modification: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import rail references and merge with api data\n",
    "rail_ref = spark.read.csv('RailReferences.csv', header=True, inferSchema=True)\n",
    "rail_ref.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc2816f7-8226-4780-9529-58856d171922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33004"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge both dfs for Station Name\n",
    "merged_df = df.join(rail_ref, df['train_platform'] == rail_ref['TiplocCode'], how='left')\n",
    "merged_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e8259-fab8-4d80-bc73-b2d4eb7af751",
   "metadata": {},
   "source": [
    "## Creating New Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5563328-98a5-4099-ab8e-2f2bb5b1fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|arrival_time_delayed_by|\n",
      "+-----------------------+\n",
      "|                  149.0|\n",
      "|                  148.0|\n",
      "|                  148.0|\n",
      "|                  148.0|\n",
      "|                  148.0|\n",
      "|                  113.0|\n",
      "|                  113.0|\n",
      "|                  113.0|\n",
      "|                  113.0|\n",
      "|                  113.0|\n",
      "|                  113.0|\n",
      "|                  112.0|\n",
      "|                  112.0|\n",
      "|                  111.0|\n",
      "|                  111.0|\n",
      "|                  100.0|\n",
      "|                  100.0|\n",
      "|                  100.0|\n",
      "|                   99.0|\n",
      "|                   99.0|\n",
      "+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create separate cols for date, time, hour\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#planned arrival\n",
    "merged_df = merged_df.withColumn('planned_arrival_date', to_date(F.col('planned_time_arrival'), 'YYYY-mm-dd'))\n",
    "merged_df = merged_df.withColumn('planned_arrival_hour', hour(F.col('planned_time_arrival')))\n",
    "\n",
    "# planned departure\n",
    "merged_df = merged_df.withColumn('planned_dep_date', to_date(F.col('planned_time_departure'), 'YYYY-mm-dd'))\n",
    "merged_df = merged_df.withColumn('planned_dep_hour', hour(F.col('planned_time_departure')))\n",
    "\n",
    "# actual arrival\n",
    "merged_df = merged_df.withColumn('actual_arrival_date', to_date(F.col('actual_arrival_time'), 'YYYY-mm-dd'))\n",
    "merged_df = merged_df.withColumn('actual_arrival_hour', hour(F.col('actual_arrival_time')))\n",
    "\n",
    "# actual departure\n",
    "merged_df = merged_df.withColumn('actual_dep_date', to_date(F.col('actual_departure_time'), 'YYYY-mm-dd'))\n",
    "merged_df = merged_df.withColumn('actual_dep_hour', hour(F.col('actual_departure_time')))\n",
    "\n",
    "# difference between planned and actual arrival time in minutes\n",
    "merged_df = merged_df.withColumn('arrival_time_delayed_by', (unix_timestamp(\"actual_arrival_time\") - unix_timestamp('planned_time_arrival'))/60)\n",
    "merged_df = merged_df.withColumn('dep_time_delayed_by', (unix_timestamp(\"actual_departure_time\") - unix_timestamp('planned_time_departure'))/60)\n",
    "\n",
    "\n",
    "merged_df.select(F.col('arrival_time_delayed_by')).filter(F.col('arrival_time_delayed_by') > 0).orderBy('arrival_time_delayed_by', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bdba3f-b22f-4453-b963-bd4952abf673",
   "metadata": {},
   "source": [
    "## Describe/ Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc1e33-8aba-4fad-a266-91ae68e57270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggestions\n",
    "# Merge the Station Rail Name Reference Table with the API data in order to provide more readable station names.\n",
    "# How would you determine the top 10 most frequently visited stations in a day?\n",
    "# What information can be explored to understand train delays?\n",
    "# Are certain stations busier than others at certain times?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e28ccb-9721-498b-a33c-3a7b3af81fbf",
   "metadata": {},
   "source": [
    "## Data Dict\n",
    "- route_id: The unique identifier for each train route.\n",
    "- unique_id: The unique identifier for each train\n",
    "- service_start_date: The date when the train service for the particular route started.\n",
    "- update_origin: Source or system from which the data was updated or retrieved.\n",
    "- train_platform: The short name for a station where the train arrives and departs.\n",
    "- working_time_pass: The planned or scheduled time for the train to pass a certain point or station.\n",
    "- working_time_arrival: The planned or scheduled time for the train to arrive at a station.\n",
    "- working_time_departure: The planned or scheduled time for the train to depart from a station.\n",
    "- planned_time_arrival: The officially planned time for the train to arrive at a station. This could be the public-facing scheduled time.\n",
    "- planned_time_departure: The officially planned time for the train to depart from a station. This could be the public-facing scheduled time.\n",
    "- platform: The platform number at the station where the train arrives and departs.\n",
    "- train_length: The physical length of the train. Number of cars.\n",
    "- actual_arrival_time: The actual time when the train arrived at a station.\n",
    "- actual_departure_time: The actual time when the train departed from a station.\n",
    "- is_delayed_arrival: A boolean flag indicating whether the train arrived late\n",
    "- is_delayed_departure: A boolean flag indicating whether the train departed late from a station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd3597-3954-4bcb-a5f7-4b5217f67e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare planned arrival/ departure with actual\n",
    "# comapre average delay\n",
    "# delays by station, count is delayed\n",
    "# look at timestamps for busiest stations\n",
    "# look at delays during night vs morning\n",
    "# col subtracting planned vs actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3290d-e8de-4599-9b32-057efc5b6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.groupBy('StationName').mean().limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790fbf1-f178-4ebe-a47c-a2f57f1b5396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df with route_id, unique_id, StationName, isDelayed\n",
    "delayed_df = merged_df[['route_id', 'unique_id', 'StationName', 'is_delayed_arrival', 'is_delayed_departure']]\n",
    "delayed_df.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0b7f6-5c82-4b50-8d7c-94db20635d07",
   "metadata": {},
   "source": [
    "### Station with most delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e816a-df1b-40c7-bca8-91d87f23c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_df.filter(F.col('is_delayed_arrival') == True).groupBy('StationName', 'is_delayed_arrival').count().orderBy('count', ascending=False).show()\n",
    "delayed_df.filter(F.col('is_delayed_departure') == True).groupBy('StationName', 'is_delayed_departure').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d2c83-0c50-4e74-b981-42470c1596a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find station with the greatest time delays\n",
    "merged_df.groupBy('StationName').sum('dep_time_delayed_by').orderBy('sum(dep_time_delayed_by)', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf036c6-dc27-4574-b2ed-893e505bef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas for additional exploration and visualization\n",
    "pandas_df = merged_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f825520c-4d72-4f3f-97bf-ac88e3815554",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df['StationName'] = pandas_df['StationName'].fillna(pandas_df['train_platform'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
